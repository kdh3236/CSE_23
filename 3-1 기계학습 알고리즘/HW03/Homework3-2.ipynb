{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2be31ff",
   "metadata": {},
   "source": [
    "Homework3 (problem 2 Bayesian Information Criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9290e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8a3e1",
   "metadata": {},
   "source": [
    "Calculate the BIC for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9196e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bic(log_likelihood, k, N):\n",
    "    \"\"\"Implements the Bayesian Information Criterion (BIC) for model selection.\"\"\"\n",
    "    return -2 * log_likelihood + k * np.log(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd349c24",
   "metadata": {},
   "source": [
    "Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703a4892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate data (N=150, d=2) ---\n",
      "True Generating Model Type: full\n",
      "Generated Data Shape: (150, 2)\n",
      "First 3 data points:\n",
      "[[1.25084825 2.72913226]\n",
      " [2.53850146 2.32733658]\n",
      " [0.66887439 1.76583271]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 0. Experiment Setup ---\n",
    "N = 150  # Number of Data Points\n",
    "d = 2    # Data Dimension\n",
    "np.random.seed(42) # Set seed for reproducibility\n",
    "\n",
    "# --- 0a. Generate Data ---\n",
    "# You can choose the model from which to generate data.\n",
    "# example: true_model_type = 'spherical', 'diagonal', or 'full'\n",
    "true_model_type = 'full' # 'full' covariance structure\n",
    "# true_model_type = 'spherical' # 'spherical' covariance structure\n",
    "# true_model_type = 'diagonal' # 'diagonal' covariance structure\n",
    "\n",
    "print(f\"--- Generate data (N={N}, d={d}) ---\")\n",
    "print(f\"True Generating Model Type: {true_model_type}\")\n",
    "if true_model_type == 'spherical': # Spherical Covariance Structure (Equal variance in all dimensions)\n",
    "    true_mean = np.array([1, 2])\n",
    "    true_sigma_sq = 1.5\n",
    "    true_cov = true_sigma_sq * np.identity(d)\n",
    "elif true_model_type == 'diagonal': # Diagonal Covariance Structure (Different variance in each dimension)\n",
    "    true_mean = np.array([1, 2])\n",
    "    true_cov = np.diag([1.0, 2.5]) # Diagonal covariance matrix\n",
    "else: # 'full'\n",
    "    true_mean = np.array([1, 2])\n",
    "    true_cov = np.array([[1.0, 0.7],  # Covariance between x1 and x2\n",
    "                         [0.7, 2.0]])\n",
    "\n",
    "data = np.random.multivariate_normal(true_mean, true_cov, N)\n",
    "\n",
    "print(f\"Generated Data Shape: {data.shape}\")\n",
    "print(f\"First 3 data points:\\n{data[:3]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89c7dabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Mean Vector from Data (MLE): [0.99238766 1.94506753]\n",
      "\n",
      "--- Results from Each Model ---\n",
      "Model: M1 (Spherical)\n",
      "  Number of Parameters (k): 3\n",
      "  Predicted Covariance Matrix (Sigma_hat):\n",
      "[[1.4180233 0.       ]\n",
      " [0.        1.4180233]]\n",
      "  Maximum Log Likelihood: -478.0711\n",
      "  BIC score: 971.1742\n",
      "\n",
      "Model: M2 (Diagonal)\n",
      "  Number of Parameters (k): 4\n",
      "  Predicted Covariance Matrix (Sigma_hat):\n",
      "[[0.95090939 0.        ]\n",
      " [0.         1.8851372 ]]\n",
      "  Maximum Log Likelihood: -469.4564\n",
      "  BIC score: 958.9553\n",
      "\n",
      "Model: M3 (Full)\n",
      "  Number of Parameters (k): 5\n",
      "  Predicted Covariance Matrix (Sigma_hat):\n",
      "[[0.95090939 0.62419829]\n",
      " [0.62419829 1.8851372 ]]\n",
      "  Maximum Log Likelihood: -451.0760\n",
      "  BIC score: 927.2051\n",
      "\n",
      "--- Final Model Selection (Lowest BIC) ---\n",
      "Selected Model: M3 (Full)\n",
      "Selected Model's BIC: 927.2051\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Each model's common mean vector MLE ---\n",
    "mu_hat_mle = np.mean(data, axis=0)\n",
    "print(f\"Predicted Mean Vector from Data (MLE): {mu_hat_mle}\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Each model's covariance estimation, parameter count, log-likelihood, and BIC calculation ---\n",
    "results = []\n",
    "\n",
    "# --- Model M1: Spherical covariance model ---\n",
    "# Parameter: mu (d), sigma^2 (1) => k1 = d + 1\n",
    "k_m1 = d + 1\n",
    "# Sigma_m1 = sigma^2 * I\n",
    "# MLE for sigma^2: (1/Nd) * sum(||x_i - mu_hat||^2)\n",
    "# or sample covariance matrix's trace average\n",
    "# S_full_mle = (1/N) * sum((x_i - mu_hat)(x_i - mu_hat)^T)\n",
    "residuals_m1 = data - mu_hat_mle\n",
    "S_full_mle = (residuals_m1.T @ residuals_m1) / N # (d x d) matrix\n",
    "\n",
    "sigma_sq_hat_m1 = np.trace(S_full_mle) / d\n",
    "Sigma_hat_m1 = sigma_sq_hat_m1 * np.identity(d)\n",
    "\n",
    "log_likelihood_m1 = multivariate_normal.logpdf(data, mean=mu_hat_mle, cov=Sigma_hat_m1, allow_singular=False).sum()\n",
    "bic_m1 = calculate_bic(log_likelihood_m1, k_m1, N)\n",
    "results.append({'model': 'M1 (Spherical)', 'k': k_m1, 'log_likelihood': log_likelihood_m1, 'bic': bic_m1, 'Sigma_hat': Sigma_hat_m1})\n",
    "\n",
    "# --- Model M2: Diagonal Covariance Model ---\n",
    "# Parameter: mu (d), sigma_j^2 (d) => k2 = d + d = 2d\n",
    "k_m2 = 2 * d\n",
    "# Sigma_m2 = diag(sigma_1^2, ..., sigma_d^2)\n",
    "# MLE for sigma_j^2: S_full_mle's diagonal elements\n",
    "Sigma_hat_m2 = np.diag(np.diag(S_full_mle))\n",
    "\n",
    "# if diagonal covariance matrix has very small variances, it may cause singular matrix issues\n",
    "# possible to add a small value (epsilon) to the diagonal for numerical stability\n",
    "# if np.any(np.diag(Sigma_hat_m2) < 1e-6):\n",
    "# Sigma_hat_m2 += np.finfo(float).eps * np.identity(d)\n",
    "\n",
    "\n",
    "log_likelihood_m2 = multivariate_normal.logpdf(data, mean=mu_hat_mle, cov=Sigma_hat_m2, allow_singular=False).sum()\n",
    "bic_m2 = calculate_bic(log_likelihood_m2, k_m2, N)\n",
    "results.append({'model': 'M2 (Diagonal)', 'k': k_m2, 'log_likelihood': log_likelihood_m2, 'bic': bic_m2, 'Sigma_hat': Sigma_hat_m2})\n",
    "\n",
    "# --- Model M3: Full Covariance Model ---\n",
    "# Parameter: mu (d), Sigma (d*(d+1)/2) => k3 = d + d*(d+1)/2\n",
    "k_m3 = d + d * (d + 1) // 2\n",
    "# Sigma_m3 = full covariance matrix\n",
    "# MLE for Sigma: S_full_mle (it is already calculated above)\n",
    "Sigma_hat_m3 = S_full_mle\n",
    "\n",
    "log_likelihood_m3 = multivariate_normal.logpdf(data, mean=mu_hat_mle, cov=Sigma_hat_m3, allow_singular=False).sum()\n",
    "bic_m3 = calculate_bic(log_likelihood_m3, k_m3, N)\n",
    "results.append({'model': 'M3 (Full)', 'k': k_m3, 'log_likelihood': log_likelihood_m3, 'bic': bic_m3, 'Sigma_hat': Sigma_hat_m3})\n",
    "\n",
    "# --- 3. Printing Results And Selecting Model ---\n",
    "print(\"--- Results from Each Model ---\")\n",
    "for res in results:\n",
    "    print(f\"Model: {res['model']}\")\n",
    "    print(f\"  Number of Parameters (k): {res['k']}\")\n",
    "    print(f\"  Predicted Covariance Matrix (Sigma_hat):\\n{res['Sigma_hat']}\")\n",
    "    print(f\"  Maximum Log Likelihood: {res['log_likelihood']:.4f}\")\n",
    "    print(f\"  BIC score: {res['bic']:.4f}\\n\")\n",
    "\n",
    "# choose the model with the lowest BIC\n",
    "best_model = min(results, key=lambda x: x['bic'])\n",
    "\n",
    "print(\"--- Final Model Selection (Lowest BIC) ---\")\n",
    "print(f\"Selected Model: {best_model['model']}\")\n",
    "print(f\"Selected Model's BIC: {best_model['bic']:.4f}\")\n",
    "\n",
    "# For futher experiments, you can change the true_model_type and run the code again.\n",
    "# (e.g., true_model_type = 'spherical' or 'diagonal')\n",
    "# You can also observe how BIC changes by varying the amount of data (N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff70b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
